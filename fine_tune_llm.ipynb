{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "27401c95",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Original label distribution:\n",
      "label\n",
      "Dangerous fire     400\n",
      "Controlled fire    400\n",
      "No fire            200\n",
      "Name: count, dtype: int64\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "from datasets import Dataset\n",
    "\n",
    "# Load your CSV\n",
    "import pandas as pd\n",
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "# Load your dataset\n",
    "df = pd.read_csv(\"fire_classification_data_1000.csv\")\n",
    "\n",
    "# Check label distribution before splitting (optional)\n",
    "print(\"Original label distribution:\")\n",
    "print(df[\"label\"].value_counts())\n",
    "\n",
    "# Split into train (80%), val (10%), test (10%)\n",
    "train_df, temp_df = train_test_split(df, test_size=0.2, stratify=df[\"label\"], random_state=42)\n",
    "val_df, test_df = train_test_split(temp_df, test_size=0.5, stratify=temp_df[\"label\"], random_state=42)\n",
    "\n",
    "# Save the splits\n",
    "train_df.to_csv(\"train.csv\", index=False)\n",
    "val_df.to_csv(\"val.csv\", index=False)\n",
    "test_df.to_csv(\"test.csv\", index=False)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "4a10aad0",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "os.environ[\"KMP_DUPLICATE_LIB_OK\"] = \"TRUE\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "53eb578a",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "7323c760032544c3b39d5d63f28e0fad",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Map:   0%|          | 0/800 [00:00<?, ? examples/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "3c795b42c6734f8280b7e601c61096c6",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Map:   0%|          | 0/100 [00:00<?, ? examples/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "4a0b9b0b8bca4e54ae00ea5e917823f6",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Map:   0%|          | 0/100 [00:00<?, ? examples/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "import pandas as pd\n",
    "from datasets import Dataset\n",
    "from transformers import AutoTokenizer\n",
    "\n",
    "# Load CSVs\n",
    "train_df = pd.read_csv(\"train.csv\")\n",
    "val_df = pd.read_csv(\"val.csv\")\n",
    "test_df = pd.read_csv(\"test.csv\")\n",
    "\n",
    "# Convert label names to integers\n",
    "label_map = {\"Controlled fire\": 0, \"Dangerous fire\": 1, \"No fire\": 2}\n",
    "train_df[\"label\"] = train_df[\"label\"].map(label_map)\n",
    "val_df[\"label\"] = val_df[\"label\"].map(label_map)\n",
    "test_df[\"label\"] = test_df[\"label\"].map(label_map)\n",
    "\n",
    "# Convert to Hugging Face Datasets\n",
    "train_dataset = Dataset.from_pandas(train_df)\n",
    "val_dataset = Dataset.from_pandas(val_df)\n",
    "test_dataset = Dataset.from_pandas(test_df)\n",
    "\n",
    "# Tokenizer\n",
    "checkpoint = \"bert-base-uncased\"\n",
    "tokenizer = AutoTokenizer.from_pretrained(checkpoint)\n",
    "\n",
    "def tokenize(batch):\n",
    "    return tokenizer(batch[\"context\"], truncation=True, padding=\"max_length\", max_length=128)\n",
    "\n",
    "train_dataset = train_dataset.map(tokenize, batched=True)\n",
    "val_dataset = val_dataset.map(tokenize, batched=True)\n",
    "test_dataset = test_dataset.map(tokenize, batched=True)\n",
    "\n",
    "# Set format for PyTorch\n",
    "train_dataset.set_format(\"torch\", columns=[\"input_ids\", \"attention_mask\", \"label\"])\n",
    "val_dataset.set_format(\"torch\", columns=[\"input_ids\", \"attention_mask\", \"label\"])\n",
    "test_dataset.set_format(\"torch\", columns=[\"input_ids\", \"attention_mask\", \"label\"])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "3027e979",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of BertForSequenceClassification were not initialized from the model checkpoint at bert-base-uncased and are newly initialized: ['classifier.bias', 'classifier.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"
     ]
    }
   ],
   "source": [
    "from transformers import AutoModelForSequenceClassification\n",
    "\n",
    "model = AutoModelForSequenceClassification.from_pretrained(checkpoint, num_labels=3)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "93a7513c",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\G15\\AppData\\Local\\Temp\\ipykernel_23092\\3029867398.py:25: FutureWarning: `tokenizer` is deprecated and will be removed in version 5.0.0 for `Trainer.__init__`. Use `processing_class` instead.\n",
      "  trainer = Trainer(\n"
     ]
    }
   ],
   "source": [
    "from transformers import TrainingArguments, Trainer\n",
    "from sklearn.metrics import classification_report, accuracy_score\n",
    "import numpy as np\n",
    "\n",
    "training_args = TrainingArguments(\n",
    "    output_dir=\"./results\",\n",
    "    eval_strategy=\"epoch\",\n",
    "    save_strategy=\"epoch\",\n",
    "    num_train_epochs=4,\n",
    "    per_device_train_batch_size=16,\n",
    "    per_device_eval_batch_size=16,\n",
    "    weight_decay=0.01,\n",
    "    logging_dir=\"./logs\",\n",
    "    logging_steps=10,\n",
    "    load_best_model_at_end=True,\n",
    "    metric_for_best_model=\"accuracy\"\n",
    ")\n",
    "\n",
    "# Define accuracy metric\n",
    "def compute_metrics(eval_pred):\n",
    "    logits, labels = eval_pred\n",
    "    preds = np.argmax(logits, axis=-1)\n",
    "    return {\"accuracy\": accuracy_score(labels, preds)}\n",
    "\n",
    "trainer = Trainer(\n",
    "    model=model,\n",
    "    args=training_args,\n",
    "    train_dataset=train_dataset,\n",
    "    eval_dataset=val_dataset,\n",
    "    tokenizer=tokenizer,\n",
    "    compute_metrics=compute_metrics\n",
    ")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "id": "593900a9",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "\n",
       "    <div>\n",
       "      \n",
       "      <progress value='200' max='200' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
       "      [200/200 01:27, Epoch 4/4]\n",
       "    </div>\n",
       "    <table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       " <tr style=\"text-align: left;\">\n",
       "      <th>Epoch</th>\n",
       "      <th>Training Loss</th>\n",
       "      <th>Validation Loss</th>\n",
       "      <th>Accuracy</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <td>1</td>\n",
       "      <td>0.000900</td>\n",
       "      <td>0.000583</td>\n",
       "      <td>1.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>2</td>\n",
       "      <td>0.000500</td>\n",
       "      <td>0.000372</td>\n",
       "      <td>1.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>3</td>\n",
       "      <td>0.000400</td>\n",
       "      <td>0.000306</td>\n",
       "      <td>1.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>4</td>\n",
       "      <td>0.000400</td>\n",
       "      <td>0.000288</td>\n",
       "      <td>1.000000</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table><p>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "\n",
       "    <div>\n",
       "      \n",
       "      <progress value='7' max='7' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
       "      [7/7 00:00]\n",
       "    </div>\n",
       "    "
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Test accuracy: 1.0\n",
      "Model and tokenizer saved successfully.\n",
      "Model and tokenizer saved successfully.\n"
     ]
    }
   ],
   "source": [
    "# Ensure the label mappings are correct\n",
    "model.config.id2label = {\n",
    "    0: \"Controlled fire\",\n",
    "    1: \"Dangerous fire\",\n",
    "    2: \"No fire\"\n",
    "}\n",
    "model.config.label2id = {v: k for k, v in model.config.id2label.items()}\n",
    "\n",
    "# Retrain the model to ensure everything is correct\n",
    "trainer.train()\n",
    "\n",
    "# Evaluate the model on the test dataset\n",
    "results = trainer.evaluate(test_dataset)\n",
    "print(\"Test accuracy:\", results[\"eval_accuracy\"])\n",
    "\n",
    "# Save the fine-tuned model and tokenizer\n",
    "import shutil\n",
    "save_path = \"fire-risk-classifier\"\n",
    "\n",
    "# Clean up the directory if it exists to avoid file locking issues\n",
    "if os.path.exists(save_path):\n",
    "    shutil.rmtree(save_path)\n",
    "\n",
    "model.save_pretrained(save_path)\n",
    "tokenizer.save_pretrained(save_path)\n",
    "\n",
    "print(\"Model and tokenizer saved successfully.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "id": "c881fd39",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Device set to use cuda:0\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Input: A candle is lit in the dark\n",
      "  Controlled fire: 1.00\n",
      "  Dangerous fire: 0.00\n",
      "  No fire: 0.00\n",
      "\n",
      "Input: Flames spreading on a wooden floor\n",
      "  Controlled fire: 0.00\n",
      "  Dangerous fire: 1.00\n",
      "  No fire: 0.00\n",
      "\n",
      "Input: A quiet park with children playing\n",
      "  Controlled fire: 0.00\n",
      "  Dangerous fire: 0.00\n",
      "  No fire: 0.99\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\G15\\anaconda3\\Lib\\site-packages\\transformers\\pipelines\\text_classification.py:106: UserWarning: `return_all_scores` is now deprecated,  if want a similar functionality use `top_k=None` instead of `return_all_scores=True` or `top_k=1` instead of `return_all_scores=False`.\n",
      "  warnings.warn(\n"
     ]
    }
   ],
   "source": [
    "# Test the saved model with the pipeline\n",
    "from transformers import pipeline\n",
    "\n",
    "classifier = pipeline(\n",
    "    \"text-classification\",\n",
    "    model=\"fire-risk-classifier\",\n",
    "    tokenizer=\"fire-risk-classifier\",\n",
    "    return_all_scores=True\n",
    ")\n",
    "\n",
    "# Run a quick test\n",
    "examples = [\n",
    "    \"A candle is lit in the dark\",\n",
    "    \"Flames spreading on a wooden floor\",\n",
    "    \"A quiet park with children playing\",\n",
    "]\n",
    "\n",
    "for text in examples:\n",
    "    out = classifier(text)\n",
    "    print(f\"\\nInput: {text}\")\n",
    "    for label_info in out[0]:\n",
    "        print(f\"  {label_info['label']}: {label_info['score']:.2f}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "id": "8f77308e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Testing model and tokenizer...\n",
      "Test output: [[{'label': 'Controlled fire', 'score': 0.0011441211681813002}, {'label': 'Dangerous fire', 'score': 0.9978399276733398}, {'label': 'No fire', 'score': 0.001015945803374052}]]\n",
      "Transformers version: 4.51.3\n",
      "Torch version: 2.5.1\n",
      "CUDA available: True\n"
     ]
    }
   ],
   "source": [
    "import traceback\n",
    "\n",
    "try:\n",
    "    # Add a test to verify the model and tokenizer\n",
    "    print(\"Testing model and tokenizer...\")\n",
    "    test_input = \"Fire spreading in a forest\"\n",
    "    test_output = classifier(test_input)\n",
    "    print(\"Test output:\", test_output)\n",
    "\n",
    "except Exception as e:\n",
    "    print(\"An error occurred:\")\n",
    "    traceback.print_exc()\n",
    "\n",
    "# Check environment details\n",
    "import transformers\n",
    "print(\"Transformers version:\", transformers.__version__)\n",
    "import torch\n",
    "print(\"Torch version:\", torch.__version__)\n",
    "print(\"CUDA available:\", torch.cuda.is_available())"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "base",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
